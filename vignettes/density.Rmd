---
title: "Density Estimation in mlr3proba"
author: "Nurul Ain Toha"
output:
  rmarkdown::html_vignette:
    toc: true
vignette: >
  %\VignetteIndexEntry{Density Estimation in mlr3proba}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  cache = FALSE,
  collapse = TRUE,
  comment = "#>"
)
set.seed(1)
lgr::get_logger("mlr3")$set_threshold("error")
```

This vignette is an introduction to performing density estimation in **mlr3proba**.

## A very quick introduction to density estimation

Density estimation is a method to find the unknown probability density function (PDF) of an underlying data set. It is a part of machine learning where it can be supervised (for conditional density) or unsupervised (unconditional density). Here, we focus on the latter and on the univariate setting. The PDF is important to give the overall probability distribution. 

## Density Task

`TaskDens` is similar to `TaskClassif` and `TaskRegr`where it has a single `target`. It is the variable that `pdf` is predicted. 

```{r}
library(mlr3proba); library(mlr3)

TaskDens$new(id = "mpg", backend = datasets::mtcars, target = "mpg" )

task = TaskDens$new(id = "mpg", backend = datasets::mtcars, target = "mpg" )

task

task$truth()[1:10]

```

## Train and Predict

```{r}

# create task and learner

task_faithful = TaskDens$new(id = "eruptions", backend = datasets::faithful, target = "eruptions")
learner = lrn("dens.kde")

# train/test split 

train_set = sample(task_faithful$nrow, 0.8 * task_faithful$nrow)
test_set = setdiff(seq_len(task_faithful$nrow), train_set)

# fit KDE and inspect model

learner$train(task_faithful, row_ids = train_set)
learner$model

# make predictions for new data

prediction = learner$predict(task_faithful, row_ids = test_set)
prediction
```

## Evaluate - pdf, cdf

Every `PredictionDens` object can predict:

* `pdf` - estimated probability density function.

Some of the learners can predict: 

* `cdf` - estimated cumulative density function


```{r}

# An example of learner that can predict is `dens.spline`

task_boston = TaskDens$new(id = "lstat", backend = MASS::Boston, target = "lstat")
learner = lrn("dens.spline")

train_set = sample(task_boston$nrow, 0.8 * task_boston$nrow)
test_set = setdiff(seq_len(task_boston$nrow), train_set)

learner$train(task_boston, row_ids = train_set)
prediction = learner$predict(task_boston, row_ids = test_set)
prediction

# An example of learner where the model can output quantile 

# In the previous example, `dens.spline` learner can output the quantile 

learner$model$quantile(0.1)

# `pdf` is evaluated using the `log-loss`

prediction$score()

```

### Probability distributions with distr6

Predicted distributions are implemented in **[distr6](https://CRAN.R-project.org/package=distr6)**, which
contains functionality for plotting and further analysis of probability distributions. See [here](https://alan-turing-institute.github.io/distr6/) for full tutorials. Briefly we will go over the most important parts for **mlr3proba**.

```{r,message=FALSE}
task = tgen("simdens")$generate(20)
learner = lrn("dens.logspline")
learner$train(task)

# The fitted model is a distr6 Distribution
learner$model

# This contains useful properties and methods
x = seq.int(0,1,length.out = 10)
learner$model$pdf(x)
learner$model$cdf(x)
learner$model$quantile(0.42)
learner$model$rand(5)

# decorators impute numerical results
distr6::decorate(learner$model, "CoreStatistics")
summary(learner$model)

# Plotting is also available
plot(learner$model)
```



